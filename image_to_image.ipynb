{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8jc8EyfruKw"
      },
      "source": [
        "# Image-to-Image Search via ResNet50\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/1QuUTy3iVR-kTPljkwplKYaJ-NTCgPEc_?usp=sharing\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>\n",
        "\n",
        "Searching visually similar images with image queries is a very popular use-case. However, using pre-trained models does not deliver the best results – the models are trained on general data that lack the particularities of your specific task. Here's where Finetuner comes in! It enables you to accomplish this easily.\n",
        "\n",
        "This guide will demonstrate how to fine-tune a ResNet model for image to image retrieval.\n",
        "\n",
        "*Note, please consider switching to GPU/TPU Runtime for faster inference.*\n",
        "\n",
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdKH0S0FrwS3"
      },
      "outputs": [],
      "source": [
        "!pip install 'finetuner[full]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EliQdGCsdL0"
      },
      "source": [
        "## Task\n",
        "\n",
        "More specifically, we will fine-tune ResNet50 on [Totally Looks Like Dataset](https://sites.google.com/view/totally-looks-like-dataset).\n",
        "The dataset consists of 6016 pairs of images (12032 in total).\n",
        "\n",
        "The dataset consists of pairs of images, these are the positive pairs. Negative pairs are constructed by taking two different images, i.e. images that are not in the same pair initially. Following this approach, we construct triplets and use the `TripletLoss`. You can find more in the [how Finetuner works](https://finetuner.jina.ai/get-started/how-it-works/#contrastive-metric-learning) section.\n",
        "\n",
        "After fine-tuning, the embeddings of positive pairs are expected to be pulled closer, while the embeddings for negative pairs are expected to be pushed away."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1sii3xdtD2y"
      },
      "source": [
        "## Data\n",
        "\n",
        "Our journey starts locally. We have to prepare the data and push it to the Jina AI Cloud and Finetuner will be able to get the dataset by its name. For this example,\n",
        "we already prepared the data, and we'll provide the names of training data (`tll-train-data`) directly to Finetuner.\n",
        "\n",
        "```{important} \n",
        "We don't require you to push data to the Jina AI Cloud by yourself. Instead of a name, you can provide a `DocumentArray` and Finetuner will do the job for you.\n",
        "```\n",
        "\n",
        "```{important}\n",
        "When working with Document where images are stored locally, please call `doc.load_uri_to_image_tensor(width=224, height=224)` or another image shape to reduce network transmission and speed up training.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L0NfPGbTkNsc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/aswin/anaconda3/envs/fast/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d3c930daf8b4f0780d0e0f1a6bbc677",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(VBox(children=(HTML(value=\"\\n<div class='custom-container'>\\n    <style>\\n        .button1 {\\n …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import finetuner\n",
        "from docarray import DocumentArray, Document\n",
        "\n",
        "finetuner.login(force=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ONpXDwFBsqQS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔐 <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">You are logged in to Jina AI</span> as <span style=\"font-weight: bold\">masapasa</span>. To log out, use <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">jina auth logout</span>.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "🔐 \u001b[1;32mYou are logged in to Jina AI\u001b[0m as \u001b[1mmasapasa\u001b[0m. To log out, use \u001b[2mjina auth logout\u001b[0m.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa65a14b618c43da959304708201d20f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39ece085c6cd4c4dac24ce5d67eecd59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd8f4dd814c742419ed48f326a0d98e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────────────── Documents Summary ──────────────────────────╮\n",
              "│                                                                       │\n",
              "│   Type                   DocumentArrayInMemory                        │\n",
              "│   Length                 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9624</span>                                         │\n",
              "│   Homogenous Documents   <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>                                         │\n",
              "│   Common Attributes      <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blob'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mime_type'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'uri'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span><span style=\"font-weight: bold\">)</span>   │\n",
              "│   Multimodal dataclass   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>                                        │\n",
              "│                                                                       │\n",
              "╰───────────────────────────────────────────────────────────────────────╯\n",
              "╭───────────────────── Attributes Summary ──────────────────────╮\n",
              "│                                                               │\n",
              "│  <span style=\"font-weight: bold\"> Attribute </span> <span style=\"font-weight: bold\"> Data type  </span> <span style=\"font-weight: bold\"> #Unique values </span> <span style=\"font-weight: bold\"> Has empty value </span>  │\n",
              "│  ───────────────────────────────────────────────────────────  │\n",
              "│   blob        <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'bytes'</span>,<span style=\"font-weight: bold\">)</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9624</span>             <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>             │\n",
              "│   id          <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span>,<span style=\"font-weight: bold\">)</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9624</span>             <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>             │\n",
              "│   mime_type   <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span>,<span style=\"font-weight: bold\">)</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>             │\n",
              "│   tags        <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'dict'</span>,<span style=\"font-weight: bold\">)</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9624</span>             <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>             │\n",
              "│   uri         <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span>,<span style=\"font-weight: bold\">)</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9624</span>             <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>             │\n",
              "│                                                               │\n",
              "╰───────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "╭────────────────────────── Documents Summary ──────────────────────────╮\n",
              "│                                                                       │\n",
              "│   Type                   DocumentArrayInMemory                        │\n",
              "│   Length                 \u001b[1;36m9624\u001b[0m                                         │\n",
              "│   Homogenous Documents   \u001b[3;92mTrue\u001b[0m                                         │\n",
              "│   Common Attributes      \u001b[1m(\u001b[0m\u001b[32m'id'\u001b[0m, \u001b[32m'blob'\u001b[0m, \u001b[32m'mime_type'\u001b[0m, \u001b[32m'uri'\u001b[0m, \u001b[32m'tags'\u001b[0m\u001b[1m)\u001b[0m   │\n",
              "│   Multimodal dataclass   \u001b[3;91mFalse\u001b[0m                                        │\n",
              "│                                                                       │\n",
              "╰───────────────────────────────────────────────────────────────────────╯\n",
              "╭───────────────────── Attributes Summary ──────────────────────╮\n",
              "│                                                               │\n",
              "│  \u001b[1m \u001b[0m\u001b[1mAttribute\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mData type \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1m#Unique values\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mHas empty value\u001b[0m\u001b[1m \u001b[0m  │\n",
              "│  ───────────────────────────────────────────────────────────  │\n",
              "│   blob        \u001b[1m(\u001b[0m\u001b[32m'bytes'\u001b[0m,\u001b[1m)\u001b[0m   \u001b[1;36m9624\u001b[0m             \u001b[3;91mFalse\u001b[0m             │\n",
              "│   id          \u001b[1m(\u001b[0m\u001b[32m'str'\u001b[0m,\u001b[1m)\u001b[0m     \u001b[1;36m9624\u001b[0m             \u001b[3;91mFalse\u001b[0m             │\n",
              "│   mime_type   \u001b[1m(\u001b[0m\u001b[32m'str'\u001b[0m,\u001b[1m)\u001b[0m     \u001b[1;36m1\u001b[0m                \u001b[3;91mFalse\u001b[0m             │\n",
              "│   tags        \u001b[1m(\u001b[0m\u001b[32m'dict'\u001b[0m,\u001b[1m)\u001b[0m    \u001b[1;36m9624\u001b[0m             \u001b[3;91mFalse\u001b[0m             │\n",
              "│   uri         \u001b[1m(\u001b[0m\u001b[32m'str'\u001b[0m,\u001b[1m)\u001b[0m     \u001b[1;36m9624\u001b[0m             \u001b[3;91mFalse\u001b[0m             │\n",
              "│                                                               │\n",
              "╰───────────────────────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_data = DocumentArray.pull('tll-train-data', show_progress=True)\n",
        "query_data = DocumentArray.pull('tll-test-query-data', show_progress=True)\n",
        "index_data = DocumentArray.pull('tll-test-index-data', show_progress=True)\n",
        "\n",
        "train_data.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUoY1jq0klwk"
      },
      "source": [
        "## Backbone model\n",
        "Now let's see which backbone models we can use. You can see available models by calling `finetuner.describe_models()`.\n",
        "\n",
        "\n",
        "For this example, we're gonna go with `resnet50`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA7IIhIOk0h0"
      },
      "source": [
        "## Fine-tuning\n",
        "\n",
        "Now that we have the training and evaluation datasets loaded as `DocumentArray`s and selected our model, we can start our fine-tuning run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qGrHfz-2kVC7"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'create_run'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfinetuner\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallback\u001b[39;00m \u001b[39mimport\u001b[39;00m EvaluationCallback, WandBLogger\n\u001b[0;32m----> 3\u001b[0m run \u001b[39m=\u001b[39m finetuner\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      4\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mresnet50\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     train_data\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtll-train-data\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     11\u001b[0m         EvaluationCallback(\n\u001b[1;32m     12\u001b[0m             query_data\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtll-test-query-data\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m             index_data\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtll-test-index-data\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m         ),\n\u001b[1;32m     15\u001b[0m         WandBLogger(),\n\u001b[1;32m     16\u001b[0m     ],\n\u001b[1;32m     17\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/hubble/__init__.py:48\u001b[0m, in \u001b[0;36mlogin_required.<locals>.arg_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     Client(jsonify\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mget_user_info()\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[39mexcept\u001b[39;00m AuthenticationRequiredError:\n\u001b[1;32m     50\u001b[0m     \u001b[39mraise\u001b[39;00m AuthenticationRequiredError(\n\u001b[1;32m     51\u001b[0m         response\u001b[39m=\u001b[39m{},\n\u001b[1;32m     52\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mJina auth token is not provided or has expired. \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m!r}\u001b[39;00m\u001b[39m requires login to Jina AI, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mplease do `jina auth login -f` or set env variable `JINA_AUTH_TOKEN` with correct token\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     54\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/finetuner/__init__.py:206\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, train_data, eval_data, run_name, description, experiment_name, model_options, loss, miner, miner_options, optimizer, optimizer_options, learning_rate, epochs, batch_size, callbacks, scheduler_step, freeze, output_dim, cpu, device, num_workers, to_onnx, csv_options, public)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39m@login_required\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m    109\u001b[0m     model: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m     public: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    134\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Run:\n\u001b[1;32m    135\u001b[0m     \u001b[39m\"\"\"Start a finetuner run!\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[39m    :param model: The name of model to be fine-tuned. Run `finetuner.list_models()` or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39m       extremely slow and inefficient.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mreturn\u001b[39;00m ft\u001b[39m.\u001b[39;49mcreate_run(\n\u001b[1;32m    207\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    208\u001b[0m         train_data\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[1;32m    209\u001b[0m         eval_data\u001b[39m=\u001b[39;49meval_data,\n\u001b[1;32m    210\u001b[0m         run_name\u001b[39m=\u001b[39;49mrun_name,\n\u001b[1;32m    211\u001b[0m         description\u001b[39m=\u001b[39;49mdescription,\n\u001b[1;32m    212\u001b[0m         experiment_name\u001b[39m=\u001b[39;49mexperiment_name,\n\u001b[1;32m    213\u001b[0m         model_options\u001b[39m=\u001b[39;49mmodel_options,\n\u001b[1;32m    214\u001b[0m         loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m    215\u001b[0m         miner\u001b[39m=\u001b[39;49mminer,\n\u001b[1;32m    216\u001b[0m         miner_options\u001b[39m=\u001b[39;49mminer_options,\n\u001b[1;32m    217\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    218\u001b[0m         optimizer_options\u001b[39m=\u001b[39;49moptimizer_options,\n\u001b[1;32m    219\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m    220\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    221\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    222\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    223\u001b[0m         scheduler_step\u001b[39m=\u001b[39;49mscheduler_step,\n\u001b[1;32m    224\u001b[0m         freeze\u001b[39m=\u001b[39;49mfreeze,\n\u001b[1;32m    225\u001b[0m         output_dim\u001b[39m=\u001b[39;49moutput_dim,\n\u001b[1;32m    226\u001b[0m         cpu\u001b[39m=\u001b[39;49mcpu,\n\u001b[1;32m    227\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    228\u001b[0m         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    229\u001b[0m         to_onnx\u001b[39m=\u001b[39;49mto_onnx,\n\u001b[1;32m    230\u001b[0m         csv_options\u001b[39m=\u001b[39;49mcsv_options,\n\u001b[1;32m    231\u001b[0m         public\u001b[39m=\u001b[39;49mpublic,\n\u001b[1;32m    232\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/hubble/__init__.py:48\u001b[0m, in \u001b[0;36mlogin_required.<locals>.arg_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     Client(jsonify\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mget_user_info()\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[39mexcept\u001b[39;00m AuthenticationRequiredError:\n\u001b[1;32m     50\u001b[0m     \u001b[39mraise\u001b[39;00m AuthenticationRequiredError(\n\u001b[1;32m     51\u001b[0m         response\u001b[39m=\u001b[39m{},\n\u001b[1;32m     52\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mJina auth token is not provided or has expired. \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m!r}\u001b[39;00m\u001b[39m requires login to Jina AI, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mplease do `jina auth login -f` or set env variable `JINA_AUTH_TOKEN` with correct token\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     54\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/finetuner/finetuner.py:179\u001b[0m, in \u001b[0;36mFinetuner.create_run\u001b[0;34m(self, model, train_data, eval_data, run_name, description, experiment_name, model_options, loss, miner, miner_options, optimizer, optimizer_options, learning_rate, epochs, batch_size, callbacks, scheduler_step, freeze, output_dim, cpu, device, num_workers, to_onnx, csv_options, public)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     experiment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_experiment(name\u001b[39m=\u001b[39mexperiment_name)\n\u001b[0;32m--> 179\u001b[0m \u001b[39mreturn\u001b[39;00m experiment\u001b[39m.\u001b[39;49mcreate_run(\n\u001b[1;32m    180\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    181\u001b[0m     train_data\u001b[39m=\u001b[39mtrain_data,\n\u001b[1;32m    182\u001b[0m     eval_data\u001b[39m=\u001b[39meval_data,\n\u001b[1;32m    183\u001b[0m     run_name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    184\u001b[0m     description\u001b[39m=\u001b[39mdescription,\n\u001b[1;32m    185\u001b[0m     model_options\u001b[39m=\u001b[39mmodel_options \u001b[39mor\u001b[39;00m {},\n\u001b[1;32m    186\u001b[0m     loss\u001b[39m=\u001b[39mloss,\n\u001b[1;32m    187\u001b[0m     miner\u001b[39m=\u001b[39mminer,\n\u001b[1;32m    188\u001b[0m     miner_options\u001b[39m=\u001b[39mminer_options,\n\u001b[1;32m    189\u001b[0m     optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[1;32m    190\u001b[0m     optimizer_options\u001b[39m=\u001b[39moptimizer_options,\n\u001b[1;32m    191\u001b[0m     learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[1;32m    192\u001b[0m     epochs\u001b[39m=\u001b[39mepochs,\n\u001b[1;32m    193\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m    194\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks \u001b[39mor\u001b[39;00m [],\n\u001b[1;32m    195\u001b[0m     scheduler_step\u001b[39m=\u001b[39mscheduler_step,\n\u001b[1;32m    196\u001b[0m     freeze\u001b[39m=\u001b[39mfreeze,\n\u001b[1;32m    197\u001b[0m     output_dim\u001b[39m=\u001b[39moutput_dim,\n\u001b[1;32m    198\u001b[0m     cpu\u001b[39m=\u001b[39mcpu,\n\u001b[1;32m    199\u001b[0m     device\u001b[39m=\u001b[39mdevice,\n\u001b[1;32m    200\u001b[0m     num_workers\u001b[39m=\u001b[39mnum_workers,\n\u001b[1;32m    201\u001b[0m     to_onnx\u001b[39m=\u001b[39mto_onnx,\n\u001b[1;32m    202\u001b[0m     csv_options\u001b[39m=\u001b[39mcsv_options,\n\u001b[1;32m    203\u001b[0m     public\u001b[39m=\u001b[39mpublic,\n\u001b[1;32m    204\u001b[0m )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'create_run'"
          ]
        }
      ],
      "source": [
        "from finetuner.callback import EvaluationCallback, WandBLogger\n",
        "\n",
        "run = finetuner.fit(\n",
        "    model='resnet50',\n",
        "    train_data='tll-train-data',\n",
        "    batch_size=128,\n",
        "    epochs=5,\n",
        "    learning_rate=1e-4,\n",
        "    device='cuda',\n",
        "    callbacks=[\n",
        "        EvaluationCallback(\n",
        "            query_data='tll-test-query-data',\n",
        "            index_data='tll-test-index-data',\n",
        "        ),\n",
        "        WandBLogger(),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gvoWipMlG5P"
      },
      "source": [
        "Let's understand what this piece of code does:\n",
        "\n",
        "* As you can see, we have to provide the `model` which we picked before.\n",
        "* We also set `run_name` and `description`, which are optional,\n",
        "but recommended in order to retrieve your run easily and have some context about it.\n",
        "* Furthermore, we had to provide names of the `train_data`.\n",
        "* We set `TripletMarginLoss`.\n",
        "* Additionally, we use `finetuner.callback.EvaluationCallback` for evaluation.\n",
        "* Lastly, we set the number of `epochs` and provide a `learning_rate`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ftSOH_olcak"
      },
      "source": [
        "## Monitoring\n",
        "\n",
        "Now that we've created a run, let's see its status. You can monitor the run by checking the status - `run.status()` - and the logs - `run.logs()` or `run.stream_logs()`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k3hTskflI7e"
      },
      "outputs": [],
      "source": [
        "# note, the fine-tuning might takes 30~ minutes\n",
        "for entry in run.stream_logs():\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8O-Ms_El-lV"
      },
      "source": [
        "Since some runs might take up to several hours, it's important to know how to reconnect to Finetuner and retrieve your runs.\n",
        "\n",
        "```python\n",
        "import finetuner\n",
        "finetuner.login()\n",
        "\n",
        "run = finetuner.get_run(run.name)\n",
        "```\n",
        "\n",
        "You can continue monitoring the runs by checking the status - `finetuner.run.Run.status()` or the logs - `finetuner.run.Run.logs()`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMpQxydypeZ3"
      },
      "source": [
        "## Evaluating\n",
        "Currently, we don't have a user-friendly way to get evaluation metrics from the `finetuner.callback.EvaluationCallback` we initialized previously.\n",
        "What you can do for now is to call `run.logs()` in the end of the run and see evaluation results:\n",
        "\n",
        "```bash\n",
        "  Training [5/5] ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76/76 0:00:00 0:03:15 • loss: 0.003\n",
        "[16:39:13] DEBUG    Metric: 'model_average_precision' Value: 0.19598                                     __main__.py:202\n",
        "           DEBUG    Metric: 'model_dcg_at_k' Value: 0.28571                                              __main__.py:202\n",
        "           DEBUG    Metric: 'model_f1_score_at_k' Value: 0.04382                                         __main__.py:202\n",
        "           DEBUG    Metric: 'model_hit_at_k' Value: 0.46013                                              __main__.py:202\n",
        "           DEBUG    Metric: 'model_ndcg_at_k' Value: 0.28571                                             __main__.py:202\n",
        "           DEBUG    Metric: 'model_precision_at_k' Value: 0.02301                                        __main__.py:202\n",
        "           DEBUG    Metric: 'model_r_precision' Value: 0.19598                                           __main__.py:202\n",
        "           DEBUG    Metric: 'model_recall_at_k' Value: 0.46013                                           __main__.py:202\n",
        "           DEBUG    Metric: 'model_reciprocal_rank' Value: 0.19598                                       __main__.py:202\n",
        "           INFO     Done ✨                                                                              __main__.py:204\n",
        "           INFO     Saving fine-tuned models ...                                                         __main__.py:207\n",
        "           INFO     Saving model 'model' in /usr/src/app/tuned-models/model ...                          __main__.py:218\n",
        "           INFO     Pushing saved model to Jina AI Cloud ...                                             __main__.py:225\n",
        "[16:39:41] INFO     Pushed model artifact ID: '62b33cb0037ad91ca7f20530'                                 __main__.py:231\n",
        "           INFO     Finished 🚀                                                                          __main__.py:233                           __main__.py:248\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l4e4GrspilM"
      },
      "source": [
        "## Saving\n",
        "\n",
        "After the run has finished successfully, you can download the tuned model on your local machine:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzfxhqeCmCa8"
      },
      "outputs": [],
      "source": [
        "artifact = run.save_artifact('resnet-model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkNHTyBkprQ0"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Now you saved the `artifact` into your host machine,\n",
        "let's use the fine-tuned model to encode a new `Document`:\n",
        "\n",
        "```{admonition} Inference with ONNX\n",
        "In case you set `to_onnx=True` when calling `finetuner.fit` function,\n",
        "please use `model = finetuner.get_model(artifact, is_onnx=True)`\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOi5qcNLplaI"
      },
      "outputs": [],
      "source": [
        "query = DocumentArray([query_data[0]])\n",
        "\n",
        "model = finetuner.get_model(artifact=artifact, device='cuda')\n",
        "\n",
        "finetuner.encode(model=model, data=query)\n",
        "finetuner.encode(model=model, data=index_data)\n",
        "\n",
        "assert query.embeddings.shape == (1, 2048)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cC46TQ9pw-H"
      },
      "source": [
        "And finally you can use the embeded `query` to find top-k visually related images within `index_data` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBYG9OKrpZ36"
      },
      "outputs": [],
      "source": [
        "query.match(index_data, limit=10, metric='cosine')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq3RVgQPCvxD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('fast')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "91cf809ebeac7834cab322c0e9393d8c235d5aedcc8b94bfe1d55e7236ca8197"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
